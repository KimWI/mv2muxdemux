import os
import sys
import math
import subprocess
import cv2
import numpy as np
import warnings
import hashlib  # ğŸ’¡ í•´ì‹œ ìƒì„±ì„ ìœ„í•´ ì¶”ê°€
from PIL import Image
from sklearn.cluster import KMeans

class MV2MasterEncoder:
    #def __init__(self, input_video, output_mv2, fps=15, quant_algo='mediancut'):
    #    self.input_video = input_video
    #    self.output_mv2 = output_mv2
    #    self.fps = fps
    #    self.width = 256
    #    self.height = 192
    #    self.temp_mp3 = "advan_temp_audio.mp3"
    #    self.quant_algo = quant_algo.lower()

    def __init__(self, input_video, output_mv2, fps=15, quant_algo='mediancut'):
        self.input_video = input_video
        self.output_mv2 = output_mv2
        self.fps = fps
        self.width = 256
        self.height = 192
        self.quant_algo = quant_algo.lower()
        
        # ğŸ’¡ [í•µì‹¬] ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì¶©ëŒ ë°©ì§€ ë¡œì§
        # ì›ë³¸ íŒŒì¼ì˜ ìˆœìˆ˜ ì´ë¦„ ì¶”ì¶œ (ì˜ˆ: SSF2T.mp4 -> SSF2T)
        base_name = os.path.splitext(os.path.basename(input_video))[0]
        
        # ì ˆëŒ€ ê²¹ì¹˜ì§€ ì•Šë„ë¡ 'ì „ì²´ ê²½ë¡œ + í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ID(PID)'ë¥¼ ì‹œë“œë¡œ ì‚¬ìš©
        unique_seed = f"{input_video}_{os.getpid()}".encode('utf-8')
        hash_str = hashlib.md5(unique_seed).hexdigest()[:8] # 8ìë¦¬ ì§§ì€ í•´ì‹œ
        
        # ê²°ê³¼ë¬¼ ì˜ˆì‹œ: temp_audio_SSF2T_a1b2c3d4.mp3
        self.temp_mp3 = f"temp_audio_{base_name}_{hash_str}.mp3"
    # ==========================================================
    # 1. ì»¬ëŸ¬ ìœ í‹¸ë¦¬í‹° (ì˜¤ë²„í”Œë¡œìš° ë°©ì§€ ì ìš©)
    # ==========================================================
    def _rgb888_to_333(self, rgb):
        r, g, b = [int(round((c / 255.0) * 7)) for c in rgb]
        return (r, g, b)

    def _rgb333_to_888(self, rgb333):
        r, g, b = rgb333
        return (r * 255 // 7, g * 255 // 7, b * 255 // 7)

    def _color_dist(self, c1, c2):
        return (int(c1[0]) - int(c2[0]))**2 + \
               (int(c1[1]) - int(c2[1]))**2 + \
               (int(c1[2]) - int(c2[2]))**2

    # ==========================================================
    # 2. ê³ ê¸‰ íŒ”ë ˆíŠ¸ ì¶”ì¶œ (Edge-Weighted + Anchoring)
    # ==========================================================
    def _extract_palette(self, img_array):
        pixels = img_array.reshape(-1, 3)
        
        # [í•µì‹¬ 1] OpenCV Canny ì—£ì§€ ê²€ì¶œì„ ì´ìš©í•´ ê²½ê³„ì„  í”½ì…€ ì¶”ì¶œ
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, threshold1=50, threshold2=150)
        edge_pixels = img_array[edges == 255]
        
        # ê²½ê³„ì„  í”½ì…€ì— 5ë°°ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ë°°ì—´ì„ ë»¥íŠ€ê¸°í•¨
        if len(edge_pixels) > 0:
            weighted_pixels = np.vstack([pixels] + [edge_pixels] * 5)
        else:
            weighted_pixels = pixels

        unique_colors = np.unique(weighted_pixels, axis=0)
        
        # 1ë²ˆ íŒ”ë ˆíŠ¸ëŠ” ë¬´ì¡°ê±´ 'ìˆœìˆ˜ ê²€ì€ìƒ‰'ìœ¼ë¡œ ê³ ì •í•  ê²ƒì´ë¯€ë¡œ, ì•Œê³ ë¦¬ì¦˜ì€ 14ê°œë§Œ ì°¾ë„ë¡ ì§€ì‹œ
        target_colors = 14
        raw_pal = []
        
        if len(unique_colors) <= target_colors:
            raw_pal = [tuple(c) for c in unique_colors]
            
        elif self.quant_algo == 'kmeans':
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                # ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ K-Means ìˆ˜í–‰
                kmeans = KMeans(n_clusters=target_colors, n_init=1, max_iter=10, random_state=42).fit(weighted_pixels)
                raw_pal = [tuple(c) for c in kmeans.cluster_centers_]
                
        else:
            # Pillowì˜ C-Engineì„ ì†ì´ê¸° ìœ„í•´, ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ 1D í”½ì…€ ë°°ì—´ì„ (1, ê¸¸ì´, 3) í˜•íƒœì˜ ì–‡ê³  ê¸´ ì´ë¯¸ì§€ë¡œ ë³€ì¡°
            aug_img_array = weighted_pixels.reshape(1, -1, 3).astype(np.uint8)
            img = Image.fromarray(aug_img_array)
            method = Image.Quantize.MEDIANCUT if self.quant_algo == 'mediancut' else Image.Quantize.FASTOCTREE
            
            q_img = img.quantize(colors=target_colors, method=method)
            pal_data = q_img.getpalette()
            
            if pal_data:
                for i in range(0, min(target_colors * 3, len(pal_data)), 3):
                    raw_pal.append((pal_data[i], pal_data[i+1], pal_data[i+2]))

        # [í•µì‹¬ 2] ì–´ì¤‘ê°„í•œ íƒí•œ ìƒ‰ìƒ(ë‹¤í¬ ê·¸ë ˆì´, ë‹¤í¬ ë¸”ë£¨ ë“±) ì œê±°
        # ìˆœìˆ˜ ê²€ì€ìƒ‰(0,0,0)ê³¼ ì—­í• ì´ ê²¹ì³ íŒ”ë ˆíŠ¸ë¥¼ ë‚­ë¹„í•˜ëŠ” ê²ƒì„ ë§‰ìŠµë‹ˆë‹¤.
        filtered_pal = [c for c in raw_pal if sum(c) > 45]

        # [í•µì‹¬ 3] ì»¬ëŸ¬ ì•µì»¤ë§: ë¬´ì¡°ê±´ ì²« ë²ˆì§¸ ìŠ¬ë¡¯ì— ìˆœìˆ˜ ê²€ì€ìƒ‰ì„ ê°•ì œ ë°•ì œ
        final_pal = [(0, 0, 0)] + filtered_pal

        # 15ê°œê°€ ì•ˆ ì±„ì›Œì¡Œë‹¤ë©´ ë¹ˆ ê³µê°„ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ ë§ˆì € ì±„ì›€
        while len(final_pal) < 15:
            final_pal.append((0, 0, 0))

        # MSX2 í•˜ë“œì›¨ì–´ ì»¬ëŸ¬(333) ê·œê²©ìœ¼ë¡œ ì–‘ìí™”
        pal_333 = [self._rgb888_to_333(c) for c in final_pal[:15]]
        return pal_333

    # ==========================================================
    # 3. MSX2 VRAM ë³€í™˜ (Color Clash ì œì–´)
    # ==========================================================
    def encode_vram_block(self, img_array):
        pal_333 = self._extract_palette(img_array)
        pal_888 = [(0,0,0)] + [self._rgb333_to_888(p) for p in pal_333]
        
        pgt = bytearray(6144)
        ct = bytearray(6144)
        
        for y in range(self.height):
            for cx in range(32):
                x_start = cx * 8
                block_pixels = img_array[y, x_start:x_start+8]
                
                mapped = []
                for px in block_pixels:
                    dists = [self._color_dist(px, p) for p in pal_888[1:16]]
                    mapped.append(np.argmin(dists) + 1)
                
                unique, counts = np.unique(mapped, return_counts=True)
                sorted_colors = unique[np.argsort(-counts)]
                fg = sorted_colors[0]
                bg = sorted_colors[1] if len(sorted_colors) > 1 else fg
                
                p_byte = 0
                for i in range(8):
                    px_idx = mapped[i]
                    if self._color_dist(pal_888[px_idx], pal_888[fg]) <= self._color_dist(pal_888[px_idx], pal_888[bg]):
                        p_byte |= (1 << (7 - i))
                        
                b_idx = (y // 8) * 32 + cx
                off = (b_idx * 8) + (y % 8)
                pgt[off] = p_byte
                ct[off] = (fg << 4) | bg

        pal_bytes = bytearray(30)
        for i in range(15):
            r, g, b = pal_333[i]
            pal_bytes[i*2] = (r << 4) | b
            pal_bytes[i*2 + 1] = g
            
        return pgt, ct, pal_bytes

    # ==========================================================
    # 4. Muxing ë° ì¡°ë¦½ íŒŒì´í”„ë¼ì¸
    # ==========================================================
    def run(self):
        print(f"[*] 1. FFmpegìœ¼ë¡œ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘ (128kbps MP3)...")
        subprocess.run([
            "ffmpeg", "-y", "-i", self.input_video, 
            "-vn", "-acodec", "libmp3lame", "-ac", "2", "-ar", "44100", "-b:a", "128k", 
            self.temp_mp3
        ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

        with open(self.temp_mp3, "rb") as f:
            mp3_data = f.read()

        print(f"[*] 2. ë¹„ë””ì˜¤ ë¶„ì„ ë° MV2 Muxing ì‹œì‘ (ì•Œê³ ë¦¬ì¦˜: {self.quant_algo.upper()})...")
        cap = cv2.VideoCapture(self.input_video)
        
        if not cap.isOpened():
            print("âŒ ë™ì˜ìƒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        orig_fps = cap.get(cv2.CAP_PROP_FPS)
        if orig_fps == 0 or math.isnan(orig_fps):
            orig_fps = 30.0
            
        out_f = open(self.output_mv2, "wb")
        
        header = bytearray(512)
        header[0:4] = b'MV2 '
        out_f.write(header)

        mp3_offset = 0
        audio_bytes_per_sec = 128000 // 8
        frame_idx = 0

        while cap.isOpened():
            cap.set(cv2.CAP_PROP_POS_FRAMES, int(frame_idx * (orig_fps / self.fps)))
            ret, frame = cap.read()
            if not ret or mp3_offset >= len(mp3_data):
                break

            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(frame_rgb).resize((self.width, self.height), Image.Resampling.LANCZOS)
            
            pgt, ct, pal = self.encode_vram_block(np.array(img))
            
            payload_size = 15872 if frame_idx == 0 else 16384
            block = bytearray(b'\x55' * payload_size)
            
            block[0:6144] = pgt
            block[6144:12288] = ct
            block[12288:12318] = pal
            
            target_audio = int((frame_idx + 1) * (audio_bytes_per_sec / self.fps))
            bytes_needed = target_audio - mp3_offset
            
            size_indicator = math.ceil(bytes_needed / 32)
            size_indicator = max(1, min(128, size_indicator))
            chunk_size = size_indicator * 32
            
            block[12800] = size_indicator
            
            audio_chunk = mp3_data[mp3_offset : mp3_offset + chunk_size]
            if len(audio_chunk) < chunk_size:
                audio_chunk += b'\x55' * (chunk_size - len(audio_chunk))
            
            block[12801 : 12801 + chunk_size] = audio_chunk
            mp3_offset += chunk_size
            
            out_f.write(block)
            
            if frame_idx % 30 == 0:
                print(f"  > ì¸ì½”ë”© ì§„í–‰ ì¤‘... {frame_idx} í”„ë ˆì„ ì™„ë£Œ")
            frame_idx += 1

        cap.release()
        
        # [í•µì‹¬ 4] ì—­ê³µí•™ìœ¼ë¡œ ì•Œì•„ë‚¸ ì˜¤ë¦¬ì§€ë„ AVGENì˜ ì™„ë²½í•œ EOF ì‹œê·¸ë‹ˆì²˜ ë¸”ë¡ ìƒì„±
        print("[*] 3. MSX ì‹¤ê¸° ì •ìƒ ì¢…ë£Œë¥¼ ìœ„í•œ ì˜¤ë¦¬ì§€ë„ EOF í”Œë˜ê·¸ ì¶”ê°€ ì¤‘...")
        eof_block = bytearray(16384) 
        eof_block[12318] = 0x01  # ì‹¤ê¸° í”Œë ˆì´ì–´ ì¢…ë£Œ í”Œë˜ê·¸
        for i in range(9):
            eof_block[12320 + i] = 0x0F
        eof_block[12800] = 0x22
        
        out_f.write(eof_block)
        out_f.close()
        
        if os.path.exists(self.temp_mp3): os.remove(self.temp_mp3)
        print(f"[!] ì™„ë²½í•œ MSX2 MV2 íŒŒì¼ ìƒì„± ì™„ë£Œ: {self.output_mv2}")

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("ì‚¬ìš©ë²•: python mv2_encoder_advanced.py [ì…ë ¥.mp4] [ì¶œë ¥.mv2] [ì•Œê³ ë¦¬ì¦˜: kmeans/mediancut/octree]")
        sys.exit(1)
    
    algo = sys.argv[3] if len(sys.argv) > 3 else 'mediancut'
    print(f"[*] ì„ íƒëœ ì–‘ìí™” ì•Œê³ ë¦¬ì¦˜: {algo.upper()}")
    
    encoder = MV2MasterEncoder(sys.argv[1], sys.argv[2], quant_algo=algo)
    encoder.run()
